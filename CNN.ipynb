{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mr-nudo/intelligent-tools/blob/master/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting global seed"
      ],
      "metadata": {
        "id": "zZuVY2-0MTyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Set a seed value\n",
        "seed_value = 25\n",
        "\n",
        "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
        "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
        "\n",
        "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
        "random.seed(seed_value)\n",
        "\n",
        "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
        "tf.random.set_seed(seed_value)\n",
        "\n"
      ],
      "metadata": {
        "id": "HKamNZg2IaEJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the libraries"
      ],
      "metadata": {
        "id": "97Ma8Id3CRwi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHiAzAjXCPk9"
      },
      "outputs": [],
      "source": [
        "# TODO: Import other necessary libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the dataset"
      ],
      "metadata": {
        "id": "1Hp5ba5uCcPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Populate the create_image_generators() function\n",
        "def create_image_generators(train_dir, target_size=(150, 150), batch_size=20, val_split=0.2):\n",
        "    \"\"\"\n",
        "    Create training and validation generators for image data.\n",
        "\n",
        "    Parameters:\n",
        "    - base_dir: Path to the base directory where the 'train' folder is located.\n",
        "    - target_size: Tuple of integers, the dimensions to which all images found will be resized.\n",
        "    - batch_size: Integer, size of the batches of data.\n",
        "    - val_split: Float, the fraction of images reserved for validation.\n",
        "\n",
        "    Returns:\n",
        "    - train_generator: Training data generator.\n",
        "    - validation_generator: Validation data generator.\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: Creating Image Data Generator for both training and validation\n",
        "\n",
        "    # TODO: Create a training data generator\n",
        "\n",
        "    # TODO: Create a validation data generator\n",
        "\n",
        "    return train_generator, validation_generator\n",
        "\n",
        "train_dir = 'path_to_cnn_train'\n",
        "train_generator, validation_generator = create_image_generators(train_dir)"
      ],
      "metadata": {
        "id": "LiNAdetiEKWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_generator_info(generator):\n",
        "    \"\"\"\n",
        "    Print information about a data generator.\n",
        "\n",
        "    Parameters:\n",
        "    - generator: The data generator (train or validation).\n",
        "    \"\"\"\n",
        "    # Number of images\n",
        "    num_images = generator.samples\n",
        "    # Batch size\n",
        "    batch_size = generator.batch_size\n",
        "    # Class indices\n",
        "    class_indices = generator.class_indices\n",
        "    # Number of classes\n",
        "    num_classes = generator.num_classes\n",
        "    # Filenames\n",
        "    filenames = generator.filenames\n",
        "\n",
        "    print(f\"Number of images: {num_images}\")\n",
        "    print(f\"Batch size: {batch_size}\")\n",
        "    print(f\"Class indices: {class_indices}\")\n",
        "    print(f\"Number of classes: {num_classes}\")\n",
        "    print(f\"Number of filenames loaded: {len(filenames)}\")  # Number of filenames might be large\n",
        "\n",
        "# Example usage:\n",
        "print(\"Training Generator Info:\")\n",
        "print_generator_info(train_generator)\n",
        "print(\"\\nValidation Generator Info:\")\n",
        "print_generator_info(validation_generator)\n"
      ],
      "metadata": {
        "id": "UkHinbTfGrMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the CNN model"
      ],
      "metadata": {
        "id": "ZNxJd0G6tpDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = # TODO: Define the CNN architecture\n",
        "\n",
        "# Print the model summary\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "xLH3s2vLtm73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = model.count_params()\n",
        "print(f\"Total number of parameters: {total_params}\")"
      ],
      "metadata": {
        "id": "EHz811TyHprz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile and fit the CNN model"
      ],
      "metadata": {
        "id": "fUWSbDNyF6Y2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Compile the model\n",
        "\n",
        "\n",
        "# TODO: Fit the model"
      ],
      "metadata": {
        "id": "eLgJNKp2GGaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot Training and Validation accuracies"
      ],
      "metadata": {
        "id": "r3YFd6rwXd-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Plot training & validation accuracy values"
      ],
      "metadata": {
        "id": "tXAcGZGZNtSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot Training and Validation losses"
      ],
      "metadata": {
        "id": "7GqfGGhsXlPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Plot training & validation accuracy losses"
      ],
      "metadata": {
        "id": "1wXkxt1dXnNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing\n"
      ],
      "metadata": {
        "id": "Ye_eGE4WIzc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_display_predict_image(img_path, model, size=(150, 150)):\n",
        "    \"\"\"\n",
        "    Load, preprocess, display, and predict the class of an image using a given model.\n",
        "\n",
        "    Parameters:\n",
        "    - img_path: String, path to the image file.\n",
        "    - model: TensorFlow/Keras model that will be used to predict the image.\n",
        "    - size: Tuple of integers, target size of the image (height, width).\n",
        "    \"\"\"\n",
        "    # Load an image file to PIL format, target size can be adjusted\n",
        "    # TODO\n",
        "\n",
        "    # Convert the PIL image to a numpy array\n",
        "    # TODO\n",
        "\n",
        "    # Add a dimension to transform the array into a batch shape\n",
        "    # TODO\n",
        "\n",
        "    # Normalize the image pixels to [0, 1]\n",
        "    # TODO\n",
        "\n",
        "    # Display the image\n",
        "    # TODO\n",
        "\n",
        "    # Predict using the provided model\n",
        "    # TODO\n",
        "\n",
        "    print(prediction)\n",
        "    print(\"Polar Bear\" if prediction[0][0] > 0.5 else \"Not Polar Bear\")"
      ],
      "metadata": {
        "id": "49lmif2hKRWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference for test_1.jpg"
      ],
      "metadata": {
        "id": "gX9y766XI4OI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = # TODO: set path to test_1.jpg\n",
        "load_display_predict_image(img_path, model)\n",
        "\n"
      ],
      "metadata": {
        "id": "oamVftqOJOaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference for test_2.jpg"
      ],
      "metadata": {
        "id": "ybPCYPWWJB9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = # TODO: set path to test_2.jpg\n",
        "load_display_predict_image(img_path, model)"
      ],
      "metadata": {
        "id": "RYUgb7ikJPHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference for test_3.jpg"
      ],
      "metadata": {
        "id": "uJfcyk9KJGVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = # TODO: set path to test_3.jpg\n",
        "load_display_predict_image(img_path, model)"
      ],
      "metadata": {
        "id": "HUVm5I0mJPnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference for test_4.jpg"
      ],
      "metadata": {
        "id": "i4rfrQyiJISx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = # TODO: set path to test_4.jpg\n",
        "load_display_predict_image(img_path, model)"
      ],
      "metadata": {
        "id": "Cn6_uWrgJQLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference for test_5.jpg"
      ],
      "metadata": {
        "id": "F8Sb43v4JJ4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = # TODO: set path to test_5.jpg\n",
        "load_display_predict_image(img_path, model)"
      ],
      "metadata": {
        "id": "brpZdH3OJQuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference for test_6.jpg"
      ],
      "metadata": {
        "id": "SidZ-Qp5JMSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = # TODO: set path to test_6.jpg\n",
        "load_display_predict_image(img_path, model)"
      ],
      "metadata": {
        "id": "Fu4OmAPMJSts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize layer activations"
      ],
      "metadata": {
        "id": "bz6O-tG6gnVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess an image\n",
        "def load_image(img_path, size=(150,150)):\n",
        "    img = image.load_img(img_path, target_size=size)\n",
        "    img_tensor = image.img_to_array(img)\n",
        "    img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "    img_tensor /= 255.\n",
        "    return img_tensor\n",
        "\n",
        "# Define a function to display the activations\n",
        "def display_layer_activations(activations, model):\n",
        "    layer_names = [layer.name for layer in model.layers[:4]]\n",
        "    images_per_row = 16\n",
        "\n",
        "    for layer_name, layer_activation in zip(layer_names, activations):\n",
        "        n_features = layer_activation.shape[-1]\n",
        "        size = layer_activation.shape[1]\n",
        "        n_cols = n_features // images_per_row\n",
        "        display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
        "\n",
        "        for col in range(n_cols):\n",
        "            for row in range(images_per_row):\n",
        "                channel_image = layer_activation[0, :, :, col * images_per_row + row]\n",
        "                channel_image -= channel_image.mean()\n",
        "                channel_image = np.maximum(channel_image, 0) / max(channel_image.std(), 1e-5)\n",
        "                channel_image *= 64\n",
        "                channel_image += 128\n",
        "                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
        "                display_grid[col * size : (col + 1) * size,\n",
        "                             row * size : (row + 1) * size] = channel_image\n",
        "\n",
        "        scale = 1. / size\n",
        "        plt.figure(figsize=(scale * display_grid.shape[1], scale * display_grid.shape[0]))\n",
        "        plt.title(layer_name)\n",
        "        plt.grid(False)\n",
        "        plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "fyuveR5Hg_Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Define a function to create a model that returns output from each layer\n",
        "def get_layer_outputs(model, img_tensor):\n",
        "    # Extracts outputs for all layers up to the last MaxPooling layer (index 3)\n",
        "\n",
        "    # Creates a new model that will return these outputs, given the model input\n",
        "\n",
        "    # Returns a list of numpy arrays, one array per layer activation\n",
        "\n",
        "    return activations\n",
        "\n",
        "\n",
        "# Load and preprocess an image\n",
        "img_path = 'set path to test_4.jpg'\n",
        "new_image = load_image(img_path)\n",
        "\n",
        "# Get activations and display them\n",
        "activations = get_layer_outputs(model, new_image)\n",
        "display_layer_activations(activations, model)"
      ],
      "metadata": {
        "id": "YQxPc59jglOk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}