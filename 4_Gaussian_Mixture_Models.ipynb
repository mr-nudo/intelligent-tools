{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mr-nudo/intelligent-tools/blob/master/4_Gaussian_Mixture_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Gaussian Mixture Models for generating new faces"
      ],
      "metadata": {
        "id": "N5EIeKD2bIPF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training a Gaussian mixture model on the Olivetti faces dataset."
      ],
      "metadata": {
        "id": "ancaeKWCQZ2A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First get the olivetti data sets."
      ],
      "metadata": {
        "id": "zAOwK1fb2OIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "\n",
        "olivetti = fetch_olivetti_faces()"
      ],
      "metadata": {
        "id": "wj8K-AVpbJaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(olivetti.DESCR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qAVa2jdbJ4b",
        "outputId": "03d37cae-2c9c-4128-f21e-e427cf8559e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _olivetti_faces_dataset:\n",
            "\n",
            "The Olivetti faces dataset\n",
            "--------------------------\n",
            "\n",
            "`This dataset contains a set of face images`_ taken between April 1992 and \n",
            "April 1994 at AT&T Laboratories Cambridge. The\n",
            ":func:`sklearn.datasets.fetch_olivetti_faces` function is the data\n",
            "fetching / caching function that downloads the data\n",
            "archive from AT&T.\n",
            "\n",
            ".. _This dataset contains a set of face images: https://cam-orl.co.uk/facedatabase.html\n",
            "\n",
            "As described on the original website:\n",
            "\n",
            "    There are ten different images of each of 40 distinct subjects. For some\n",
            "    subjects, the images were taken at different times, varying the lighting,\n",
            "    facial expressions (open / closed eyes, smiling / not smiling) and facial\n",
            "    details (glasses / no glasses). All the images were taken against a dark\n",
            "    homogeneous background with the subjects in an upright, frontal position \n",
            "    (with tolerance for some side movement).\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    =================   =====================\n",
            "    Classes                                40\n",
            "    Samples total                         400\n",
            "    Dimensionality                       4096\n",
            "    Features            real, between 0 and 1\n",
            "    =================   =====================\n",
            "\n",
            "The image is quantized to 256 grey levels and stored as unsigned 8-bit \n",
            "integers; the loader will convert these to floating point values on the \n",
            "interval [0, 1], which are easier to work with for many algorithms.\n",
            "\n",
            "The \"target\" for this database is an integer from 0 to 39 indicating the\n",
            "identity of the person pictured; however, with only 10 examples per class, this\n",
            "relatively small dataset is more interesting from an unsupervised or\n",
            "semi-supervised perspective.\n",
            "\n",
            "The original dataset consisted of 92 x 112, while the version available here\n",
            "consists of 64x64 images.\n",
            "\n",
            "When using these images, please give credit to AT&T Laboratories Cambridge.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "olivetti.target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEci5cW9bMK6",
        "outputId": "60305607-8aae-44a9-880f-40f2d3493ab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,\n",
              "        3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,\n",
              "        5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,\n",
              "        6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,\n",
              "        8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10,\n",
              "       10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
              "       11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13,\n",
              "       13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15,\n",
              "       15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
              "       17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18,\n",
              "       18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20,\n",
              "       20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22,\n",
              "       22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23,\n",
              "       23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25,\n",
              "       25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27,\n",
              "       27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
              "       28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30,\n",
              "       30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32,\n",
              "       32, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33,\n",
              "       34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 35, 35, 35, 35, 35, 35, 35,\n",
              "       35, 35, 35, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 37, 37, 37, 37,\n",
              "       37, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 39,\n",
              "       39, 39, 39, 39, 39, 39, 39, 39, 39])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Train a Gaussian mixture model on the Olivetti faces dataset. If you are training on your local system, you can use the dataset as is. But if you are using Google Colab, you will have to reduce your data, otherwise, your RAM will crash. For now, we will provide you with the code for PCA dimensionality reduction, which you will learn what it does in the following weeks. You can use the provided code for that part."
      ],
      "metadata": {
        "id": "WDYphjVcw4Vq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Shuffle and split the data to have a better distribution using StratifiedShuffleSplit. Split the data to train set, test set and validation set."
      ],
      "metadata": {
        "id": "9coPBwNw2VvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "strat_split = StratifiedShuffleSplit(n_splits=1, test_size=40, random_state=42)\n",
        "train_valid_idx, test_idx = next(strat_split.split(olivetti.data,\n",
        "                                                   olivetti.target))\n",
        "X_train_valid = olivetti.data[train_valid_idx]\n",
        "y_train_valid = olivetti.target[train_valid_idx]\n",
        "X_test = olivetti.data[test_idx]\n",
        "y_test = olivetti.target[test_idx]\n",
        "\n",
        "strat_split = StratifiedShuffleSplit(n_splits=1, test_size=80, random_state=43)\n",
        "train_idx, valid_idx = next(strat_split.split(X_train_valid, y_train_valid))\n",
        "X_train = X_train_valid[train_idx]\n",
        "y_train = y_train_valid[train_idx]\n",
        "X_valid = X_train_valid[valid_idx]\n",
        "y_valid = y_train_valid[valid_idx]"
      ],
      "metadata": {
        "id": "a776UkI3bPV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, y_train.shape)\n",
        "print(X_valid.shape, y_valid.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKNKyq5nbSYJ",
        "outputId": "71f5d0b0-fbc5-4a18-cf9a-bf659f84a82d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(280, 4096) (280,)\n",
            "(80, 4096) (80,)\n",
            "(40, 4096) (40,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this part is to avoid overflow of your RAM, ignore it for now. you will learn more about them on next lecture."
      ],
      "metadata": {
        "id": "5VBCHNy2dRjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(0.97)\n",
        "X_train_reduced = pca.fit_transform(X_train)\n",
        "X_valid_reduced = pca.transform(X_valid)\n",
        "X_test_reduced = pca.transform(X_test)"
      ],
      "metadata": {
        "id": "CDX6KlIJdMmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the GaussianMixture of sklearn, and with 20 number of components, train a gaussian mixture model on your data.\n",
        "\n",
        "(set your random state to 42 for reproducibility and you can use the X_train_reduced from the previous part)\n"
      ],
      "metadata": {
        "id": "JJ0oE0dl3HUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.mixture # ------ fill here\n",
        "\n",
        "gm = # ---- fill here\n",
        "y_pred = #---- fill here"
      ],
      "metadata": {
        "id": "u88BBAnVbsqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Generate 30 new faces by sampling from your model and visualize them."
      ],
      "metadata": {
        "id": "9fVI3sQdKFXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_generated_faces = #---- fill here\n",
        "generated_faces_reduced_format, y_gen_faces = # ---- fill here\n"
      ],
      "metadata": {
        "id": "NLVvioxPbVWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now just run this line and ignore what it does as well:D\n",
        "since your results are in reduced format, you have to use the inverse transform."
      ],
      "metadata": {
        "id": "pT02Az11eCeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generated_faces = pca.inverse_transform(generated_faces_reduced_format)"
      ],
      "metadata": {
        "id": "-odswiAZdI5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "plot your generated faces. you can use the provided function for it."
      ],
      "metadata": {
        "id": "KTDyqsX23s5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_faces(faces, labels, n_cols=5):\n",
        "    faces = #---- fill here: Turn your results to picture format by reshaping it\n",
        "                      # you are supposed to check the original dataset and\n",
        "                      # figure out what was the resolution of the original images\n",
        "    n_rows = (len(faces) - 1) // n_cols + 1\n",
        "    plt.figure(figsize=(n_cols, n_rows * 1.1))\n",
        "    for index, (face, label) in enumerate(zip(faces, labels)):\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(face, cmap=\"gray\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(label)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_xzeFsakI3AZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_faces(generated_faces, y_gen_faces)"
      ],
      "metadata": {
        "id": "mHgRP5ztcGY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Take the first 5 images of your dataset and create 15 changed images. The first five(changed) images must be rotated 90 degrees counterclockwise. The second five (changed) images must beflipped. The third five images must be darker than the original images (multiply their channels by 0.3.)"
      ],
      "metadata": {
        "id": "RAmbfreqtEYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "n_rotated = 5\n",
        "rotated = # --- fill here\n",
        "rotated = rotated.reshape(-1, 64*64)\n",
        "y_rotated = y_train[:n_rotated]\n",
        "\n",
        "n_flipped = 5\n",
        "flipped = # --- fill here\n",
        "flipped = flipped.reshape(-1, 64*64)\n",
        "y_flipped = y_train[:n_flipped]\n",
        "\n",
        "n_darkened = 5\n",
        "darkened = X_train[:n_darkened].copy()\n",
        "# --- fill here\n",
        "y_darkened = y_train[:n_darkened]\n",
        "\n",
        "X_bad_faces = np.r_[rotated, flipped, darkened]\n",
        "y_bad = np.concatenate([y_rotated, y_flipped, y_darkened])\n",
        "\n",
        "plot_faces(X_bad_faces, y_bad)"
      ],
      "metadata": {
        "id": "EdYyjriEtLDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Compute the log-likelihood of each sample. (you can use the gm methods.) Compare these log-likelihoods with the main data scores (maybe for the first 15 samples). Explain the results and describe how we use GMMs for anomaly detection."
      ],
      "metadata": {
        "id": "PZuCtmMGth0Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ignore this part for now:D"
      ],
      "metadata": {
        "id": "E9sgbG8StxkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_bad_faces_pca = pca.transform(X_bad_faces)"
      ],
      "metadata": {
        "id": "hN7a8r6Atw3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- fill here"
      ],
      "metadata": {
        "id": "tHA46vglt92r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- fill here"
      ],
      "metadata": {
        "id": "xJ7l8SCVt9nD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}